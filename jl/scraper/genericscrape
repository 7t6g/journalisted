#!/usr/bin/env python
""" commandline tool to grab parse article text and metadata from a given url """

import urllib2
import logging
from datetime import datetime
from optparse import OptionParser

try:
    import simplejson as json
except ImportError:
    import json

import metareadability
import decruft

import site
site.addsitedir("../pylib")
from JL import ScraperUtils
from JL import ukmedia



def context_from_url(url):
    context = {}
    context['permalink']=url
    context['srcurl']=url
    context['lastseen'] = datetime.now()
    return context

def extract(html,context):
    art = context

    headline,byline,pubdate = metareadability.extract(html,context['srcurl'])
    if headline is not None:
        art['title'] = headline
    if pubdate is not None:
        art['pubdate'] = pubdate
    if byline is not None:
        art['byline'] = byline
    else:
        art['byline'] = u''

    txt = decruft.Document(html).summary()
    art['content'] = ukmedia.SanitiseHTML(txt)
    return art


def main():
    parser = OptionParser(usage="%prog: [options] urls")
    parser.add_option('-v', '--verbose', action='store_true')
    parser.add_option('-V', '--debug', action='store_true')
    parser.add_option('-d', '--dry_run', action='store_true')
    parser.add_option('-f', '--force_rescrape', action='store_true')
    parser.add_option('-s', '--source_feeds', dest="source_feeds", help="list of feeds, in json format")
    (options, args) = parser.parse_args()

    log_level = logging.ERROR
    if options.debug:
        log_level = logging.DEBUG
    if options.verbose:
        log_level = logging.INFO

    logging.basicConfig(level=log_level, format='%(message)s')
    max_errors = 100

    if options.source_feeds:
        feeds = json.loads(open(options.source_feeds, "rt").read())
        arts = ScraperUtils.FindArticlesFromRSS([(f[1],f[0]) for f in feeds], None, None)
        ScraperUtils.scrape_articles(arts, extract, max_errors, options)


    else:
        # individual urls
        arts = [context_from_url(url) for url in args]

        ScraperUtils.scrape_articles(arts, extract, max_errors, options)

if __name__ == '__main__':
    main()

