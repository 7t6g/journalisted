#!/usr/bin/env python
#
# tool to try and scrape some minimal info from _any_ news article page
# title, pubdate...
#

import sys
from datetime import datetime
from optparse import OptionParser
import simplejson as json
import re
import dateutil.parser
import urlparse

import site
site.addsitedir("../pylib")
from JL import DB,ukmedia
from BeautifulSoup import BeautifulSoup, Comment

_options = None



def find_story( soup ):
    # try and identify a container around just the story part
    # id/class markers, in order of preference
    story_markers = (
        re.compile( r'\bhentry\b|\bpost\b|\bstory\b', re.IGNORECASE ),
        re.compile( r'\bcontent\b|\bmain\b|\bcontentContainer\b|\bcontent[-_]main\b|\bmainColumn\b', re.IGNORECASE )
    )

    story = None
    for pat in story_markers:
        for attr in ('id','class'):
            story = soup.find( 'div', {attr:pat} )
            if story is not None:
                if _options.debug:
                    print "find_story(): found div %s=%s" % (attr, story[attr])
                break   # got one!
        if story is not None:
            break   # got one!
    if _options.debug and story is None:
        print "find_story(): nothing"
    return story



def find_headline( soup, url ):

#    print url
    slug = slug_from_url( url )
    if slug:
        words = slug.split('-')
        finder_pat = '(.*?)'.join( [r'\b' + w + r'\b' for w in slug.split('-') ] )

        for t in soup.findAll( text=re.compile(finder_pat, re.IGNORECASE) ):
            h = t.findParent( ['h1','h2','h3','h4' ] )
            if h:
                return h
#                print "GOT: ", ukmedia.FromHTMLOneLine( h.renderContents(None) ).encode('utf-8')
#                sys.exit(0)
            
#        print "no good match for: ", slug
#    else:
#        print "no slug"
#    sys.exit(0)


    headline =  None
    # try some easy cases first:
    h = soup.find( ('h1','h2','h3'),{'class':re.compile('entry-title|headline')}) 
    if h is not None:
        if _options.debug:
            print "find_headline(): got easy one: %s class=%s" % (h.name,h['class'])
        return h

    story = find_story( soup )
    if story is None:
        # give up and just use the whole page
        story = soup

    # might be one with .headline class...
    h = story.find( ('h1','h2','h3'), {'class':re.compile('title|headline')})
    if h is not None:
        if _options.debug:
            print "find_headline(): got one with a marker: %s class=%s" % (h.name,h['class'])
        return h
    # just go for biggest h[123] we can find
    for element in ('h1','h2','h3'):
        h = story.find(element)
        if h is not None:
            if _options.debug:
                print "find_headline(): got bare one: %s class=%s" % (h.name,h['class'])
            return h

    if _options.debug:
        print "find_headline(): nothing"
    return None



def extract_pubdate( soup ):
    pubdate = None

    # look for hAtom/hNews dates...
    # <abbr class="foo" title="YYYY-MM-DDTHH:MM:SS+ZZ:ZZ">
    abbr = soup.find( 'abbr', {'class':'published'} )
    if abbr is None:
        abbr = soup.find( 'abbr', {'class':'updated'} )

    if abbr is not None:
        pubdate = dateutil.parser.parse( abbr['title'] )

    return pubdate
    # let's just leave it there for now.

    # NEVER GETS HERE


    # a bunch of things which might indicate a date/time...
    dt_markers = (
        'mon', 'tue', 'wed', 'thu' 'fri', 'sat', 'sun',
        'monday', 'tuesday','wednesday','thursday','friday','saturday','sunday',
        'jan','feb','mar','apr','may','jun',
        'jul','aug','sep','oct','nov','dec',
        'january', 'february', 'march', 'april', 'may', 'june',
        'july', 'august', 'september', 'october', 'november', 'december',
        r'2\d\d\d', r'1\d\d\d', # year
        r'\d\d:\d\d',           # time
        r'\d\d-\d\d',r'\d\d/\d\d'   # 01/02 or 01-02
    )

    t = '|'.join( [ r'\b'+marker+r'\b' for marker in dt_markers ] )
#    print t
    dt_pat = re.compile( t )

    pubdate = None
    for txt in soup.findAll( text=dt_pat ):
        try:
            rawtxt = str(txt).strip()
            pubdate = dateutil.parser.parse( txt, fuzzy=True )
            if pubdate is not None:
                break
        except Exception:
            pass

    return pubdate



def slug_from_url( url ):
    """ return the slug part of a url, or '' """
    url = re.sub('/$','',url)   # kill trailing slash
    o = urlparse.urlparse( url )
    txt = o.path.split('/')[-1]

    m = re.compile( "^[\w]+-[-\w]+$" ).match( txt )
    if m is None:
        return ''
    else:
        return m.group(0)




def extract( html, context ):
    soup = BeautifulSoup( html )

    title = u''
    h = find_headline( soup, context['url'] )
    if h is not None:
        title = ukmedia.FromHTMLOneLine( h.renderContents(None) )
    #ideas:
    # check for a slug in the url and make sure the headline corresponds
    # ditto, using page <title>

    pubdate = extract_pubdate(soup)
#    if pubdate is None:
        # give up and just use the whole page
#        pubdate = extract_date(soup)

    context['title'] = title
    context['pubdate'] = pubdate
    o = urlparse.urlparse( context['url'] )
    context['publication'] = re.sub( '^www.','',o[1] )
    return context


def main():
    global _options
    parser = OptionParser()
    parser.add_option("-d", "--debug", action="store_true", dest="debug", help="output debug information")
#    parser.add_option("-v", "--verbose", action="store_true", dest="verbose", help="output progress information")
#    parser.add_option("-j", "--json", action="store_true", dest="json", help="output results as json")

    (_options, args) = parser.parse_args()


    results = []
    for url in args:
        try:
            html = ukmedia.FetchURL( url )
            details = extract( html, {'url':url,'status':'ok'} )
        except Exception,err:
            details = {
                'url':url,
                'status':'error',
                'errormsg': str(err) }

        results.append( details )

    print( json.dumps( results ) )

if __name__ == "__main__":
    main()

