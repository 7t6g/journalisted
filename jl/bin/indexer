#!/usr/bin/env python2.4
#
import sys
import xapian
import string
from datetime import datetime
from optparse import OptionParser

import site
site.addsitedir("../pylib")
from JL import DB,ukmedia

import mysociety.config
mysociety.config.set_file("../conf/general")
xapdbpath = mysociety.config.get('JL_XAPDB')



# ids for value field we want to store along with the document
# (so we can display them in the search results)
ARTICLE_ID = 0
TITLE_ID = 1
PUBDATE_ID = 2
SRCORG_ID = 3
PERMALINK_ID = 4
JOURNOS_ID = 5


def IndexArticle( xapdb, art ):
    indexer = xapian.TermGenerator()
    stemmer = xapian.Stem("english")
    indexer.set_stemmer(stemmer)

    #print "indexing: '%s'"  %(art['title'].encode('utf-8'))
    txt = ukmedia.FromHTML( art['content'] );

    doc = xapian.Document()
#    doc.set_data(txt)

    article_id_term = 'Q' + str(art['id'])
    doc.add_term( article_id_term )

    for j in art['journos']:
        doc.add_term( 'J' + str(j['id']) )

    # add all the things we need to be able to display in search results...
    doc.add_value( ARTICLE_ID, str(art['id']) )
    doc.add_value( TITLE_ID, art['title'].encode('utf-8') )
    doc.add_value( PUBDATE_ID, art['pubdate'].isoformat() )
    doc.add_value( SRCORG_ID, str(art['srcorg']) )
    doc.add_value( PERMALINK_ID, art['permalink'] )

    # index the main text of the article...
    indexer.set_document(doc)
    indexer.index_text( txt )

    # ...and the title...
    indexer.increase_termpos()
    indexer.index_text( art['title'], 1, 'T' )

    # ...and the byline.
    indexer.increase_termpos()
    indexer.index_text( art['byline'], 1, 'B' )


    xapdb.replace_document( article_id_term, doc )



def FetchJournos( conn, article_id ):
    c = conn.cursor()
    c.execute( """
        SELECT *
            FROM ( journo_attr attr INNER JOIN journo j ON j.id=attr.journo_id )
            WHERE attr.article_id=%s
        """, (article_id) )
    journos = c.fetchall()
    if journos == None:
        journos = []
    c.close()
    return journos


def PerformIndexing( options ):
    start = datetime.now()

    conn = DB.Connect()
    xapdb = xapian.WritableDatabase(xapdbpath, xapian.DB_CREATE_OR_OPEN)

    conditions = [ "status=%s" ]
    params = [ 'a' ]
    if options.from_date:
        conditions.append( "lastscraped >= %s::date" )
        params.append( options.from_date )

    if options.to_date:
        # +1 day to include the day of to_date
        conditions.append( "lastscraped < %s::date + '1 day'::interval" )
        params.append( options.to_date )


    sql = "SELECT * FROM article WHERE " + " AND ".join( conditions )
    print sql

    c = conn.cursor()
    c.execute( sql, params );

    xapdb.begin_transaction()
    tot=0
    cnt=0
    skipped=0
    while 1:
        row = c.fetchone()
        if not row:
            break
        art = {}
        for f in ( 'title', 'content', 'byline' ):
            art[f] = row[f].decode( 'utf-8' )
        for f in ( 'id','srcorg', 'pubdate','permalink' ):
            art[f] = row[f]
        art['journos'] = FetchJournos( conn, art['id'] )

        skip = False
        if not options.replace_existing:
            skip = xapdb.term_exists( 'Q' + str(art['id']) )

        if not skip:
            IndexArticle( xapdb, art )

            cnt = cnt+1
            tot = tot+1
            if cnt >= 1000:
                cnt=0
                xapdb.commit_transaction()
                print "committed %d" %(tot)
                xapdb.begin_transaction()
        else:
            skipped = skipped+1


    # commit any leftovers
    xapdb.commit_transaction()
    print "done. committed %d, skipped %d" %(tot,skipped)

    c.close()

    fin = datetime.now()
    print "finished. took %s " % (fin-start)


def main():
    parser = OptionParser()

    parser.add_option("-f", "--from-date",
        dest="from_date",
        metavar="DATE",
        help="index articles scraped from DATE (yyyy-mm-dd) onward" )
    parser.add_option("-t", "--to-date",
        dest="to_date",
        metavar="DATE",
        help="index articles scraped up to (and including) DATE (yyyy-mm-dd)" )
    parser.add_option("-r", "--replace",
        action="store_true", dest="replace_existing",
        help="reindex articles already in the xapian db")

    (options, args) = parser.parse_args()

    PerformIndexing( options )



if __name__ == "__main__":
    main()

