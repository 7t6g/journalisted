#!/usr/bin/env python
#
# migrate articles from "journo_other_articles" to the main "article" table
# sideeffect: creates new publications.
#


import sys
import string
from datetime import datetime
from optparse import OptionParser
import urlparse
import re

import site
site.addsitedir("../pylib")
from JL import DB

__opts = None
_conn = None


def resolve_publication( domain, name ):
    """ look up a publications, return publication id or None """



    # use domain to look them up
    # want to look for both www. and bare versions
    domain = domain.lower().strip().encode( 'ascii' )
    candidates = [ domain ]
    if domain.startswith( 'www.' ):
        candidates.append( re.sub( '^www.','',domain ) )
    else:
        candidates.append( 'www.' + domain )

    c = _conn.cursor()
    c.execute( "SELECT pub_id FROM pub_domain WHERE domain in ( %s,%s )",
        (candidates[0], candidates[1]) )
    matched_domains = [ row['pub_id'] for row in c.fetchall() ]

    if len( matched_domains ) == 1:
        # got it!
        return matched_domains[0]

    elif len( matched_domains ) == 0:
        # no matching domain - try looking up by name instead
        n = name.strip().encode( 'utf-8' )
        c.execute( """SELECT pub_id FROM pub_alias a WHERE LOWER(alias)=LOWER(%s)""", (n,) )
        matched_names = [ row['pub_id'] for row in c.fetchall() ]
        if len(matched_names) == 0:
            return None     # give up
        if len(matched_names) == 1:
            return matched_names[0]
        raise Exception( "Can't disambiguate publication (domain: '%s' name: '%s') - no domains, but multiple names" % (domain,name) )

    elif len( matched_domains ) > 1:
        # more than one matching domain - try to disambiguate using name
        n = name.strip().encode( 'utf-8' )
        if n== '':
            return matched_domains[0]   # no name - just assume first match.

        sql = """SELECT pub_id FROM pub_alias WHERE LOWER(alias)=LOWER(%s) AND pub_id IN ( SELECT pub_id FROM pub_domain WHERE domain IN (%s,%s) )"""
        c.execute( sql, (n,candidates[0], candidates[1]) )
        matched_names = [ row['pub_id'] for row in c.fetchall() ]
        if len(matched_names) == 1:
            return matched_names[0]
        if len(matched_names) == 0:
            raise Exception( "Can't disambiguate publication (domain: '%s' name: '%s') - multiple domains, no names" % (domain,name) )
        if len(matched_names) > 1:
            raise Exception( "Can't disambiguate publication (domain: '%s' name: '%s') - multiple domains, multiple names" % (domain,name) )

    assert False    # shouldn't get this far




def create_publication( domain, publication ):
    if publication.strip() == u'':
        # use domain for missing publication names
        publication = unicode( domain )
        publication = re.sub( u'^www.',u'',publication )

    c = _conn.cursor()
    c.execute( """INSERT INTO organisation (id,shortname,prettyname,home_url) VALUES (DEFAULT, %s,%s,%s) RETURNING id""",
        ( domain, publication, "http://" + domain ) )
    pub_id = c.fetchone()[0]

    c.execute( """INSERT INTO pub_domain (pub_id,domain) VALUES (%s,%s)""", (pub_id,domain) )
    c.execute( """INSERT INTO pub_alias (pub_id,alias) VALUES (%s,%s)""", (pub_id,publication) )

    if _opts.verbose:
        print "new publication [%d]: %s (%s)" % ( pub_id,publication,domain)
    return pub_id



def migrate_article( art ):
    # already got it?
    cursor = _conn.cursor()
    srcid = art['permalink']
    cursor.execute( "SELECT id FROM article WHERE srcid=%s", srcid )
    existing = cursor.fetchall()
    if len(existing) > 0:
        print >>sys.stderr, "already got %s - SKIPPING." % (art['permalink'])
        return

    # 1) sort out publication (create if necessary)
    url = art['permalink'].strip()

    o = urlparse.urlparse(url)
    domain = o[1]
    domain = domain.lower()
    if domain == '':
        print >>sys.stderr, "SKIP bad/blank url (other_id=%s)" % (art['other_article_id'])
        return

    srcorg = resolve_publication( domain, art['publication'] )
    if srcorg is None:
        srcorg = create_publication( domain,art['publication'] )

    # 2) add article
    # send text to the DB as utf-8
    title = art['title'].encode( 'utf-8' )
    byline = u''
    description = u''
    pubdate = "%s" %(art['pubdate'])
    lastscraped = None
    lastseen = datetime.now()
    firstseen = lastseen
    srcurl = art['permalink']
    permalink = art['permalink']
    wordcount = None


    q = """INSERT INTO article (id,title, byline, description, lastscraped, pubdate, firstseen, lastseen, permalink, srcurl, srcorg, srcid, wordcount, last_comment_check) VALUES (DEFAULT, %s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s) RETURNING id"""
    cursor.execute( q, ( title, byline, description, lastscraped, pubdate, firstseen, lastseen, permalink, srcurl, srcorg, srcid, wordcount, lastscraped ) )
    article_id = cursor.fetchone()[0]

    # 3) attribute journo
    cursor.execute( "INSERT INTO journo_attr ( journo_id, article_id) VALUES (%s,%s)", (art['journo_id'],article_id) )

    # 4) mark article for indexing
    cursor.execute( "DELETE FROM article_needs_indexing WHERE article_id=%s", (article_id) )
    cursor.execute( "INSERT INTO article_needs_indexing (article_id) VALUES (%s)", (article_id) )

    if _opts.verbose:
        print "a%d: %s" % ( article_id, art['permalink'] )

    # 5) delete the redundant other_article
    cursor.execute( "DELETE FROM journo_other_articles WHERE id=%s", (art['other_article_id']) )

    _conn.commit()



def migrate_articles():
    c = _conn.cursor()
    c.execute( """SELECT * FROM journo_other_articles WHERE status='a'""" )
    while 1:
        row = c.fetchone()
        if row is None:
            break
        other_art = {
            'other_article_id': int( row['id'] ),
            'permalink': row['url'].decode('utf-8'),
            'title': row['title'].decode('utf-8'),
            'pubdate': row['pubdate'],
            'publication': row['publication'].decode('utf-8'),
            'journo_id': int( row['journo_id'] )
        }

        migrate_article( other_art )





def main():
    global _opts,_conn

    parser = OptionParser()
    parser.add_option("-v", "--verbose", action="store_true", dest="verbose", help="output more (by default, only suspect stuff of output)")
    (_opts, args) = parser.parse_args()
    _conn = DB.Connect()

    migrate_articles()

if __name__ == "__main__":
    main()

